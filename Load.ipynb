{"cells": [{"cell_type": "markdown", "id": "51653e15-58d5-4b8b-af58-6a8f782f032e", "metadata": {}, "source": "## assume we have hardcoded data wanted load to multiple file formats"}, {"cell_type": "code", "execution_count": 2, "id": "4bae6321-d33e-4430-9cfe-c5441426c267", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----+---------------+---------+---------+------------+\n|empId|        empName|empGender|empSalary|  empCountry|\n+-----+---------------+---------+---------+------------+\n|    1|       John Doe|     Male|  60000.0|         USA|\n|    2|     Jane Smith|   Female|  55000.0|      Canada|\n|    3|  Alice Johnson|   Female|  65000.0|          UK|\n|    4|   Bob Williams|     Male|  62000.0|   Australia|\n|    5|      Eve Davis|   Female|  70000.0|       India|\n|    6|  Charlie Brown|     Male|  58000.0|     Germany|\n|    7|   Diana Miller|   Female|  60000.0|      France|\n|    8|  Frank Johnson|     Male|  62000.0|       Spain|\n|    9|   Grace Wilson|   Female|  54000.0|       Italy|\n|   10|    Henry Davis|     Male|  68000.0|       Japan|\n|   11|   Isabel Clark|   Female|  59000.0|      Brazil|\n|   12|    Jack Turner|     Male|  63000.0|      Mexico|\n|   13|Katherine White|   Female|  67000.0|South Africa|\n|   14|   Louis Harris|     Male|  56000.0|      Russia|\n|   15|        Mia Lee|   Female|  61000.0|       China|\n+-----+---------------+---------+---------+------------+\n\nroot\n |-- empId: long (nullable = true)\n |-- empName: string (nullable = true)\n |-- empGender: string (nullable = true)\n |-- empSalary: double (nullable = true)\n |-- empCountry: string (nullable = true)\n\n"}, {"data": {"text/plain": "15"}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": "emp_data = [\n    (1, \"John Doe\", \"Male\", 60000.0, \"USA\"),\n    (2, \"Jane Smith\", \"Female\", 55000.0, \"Canada\"),\n    (3, \"Alice Johnson\", \"Female\", 65000.0, \"UK\"),\n    (4, \"Bob Williams\", \"Male\", 62000.0, \"Australia\"),\n    (5, \"Eve Davis\", \"Female\", 70000.0, \"India\"),\n    (6, \"Charlie Brown\", \"Male\", 58000.0, \"Germany\"),\n    (7, \"Diana Miller\", \"Female\", 60000.0, \"France\"),\n    (8, \"Frank Johnson\", \"Male\", 62000.0, \"Spain\"),\n    (9, \"Grace Wilson\", \"Female\", 54000.0, \"Italy\"),\n    (10, \"Henry Davis\", \"Male\", 68000.0, \"Japan\"),\n    (11, \"Isabel Clark\", \"Female\", 59000.0, \"Brazil\"),\n    (12, \"Jack Turner\", \"Male\", 63000.0, \"Mexico\"),\n    (13, \"Katherine White\", \"Female\", 67000.0, \"South Africa\"),\n    (14, \"Louis Harris\", \"Male\", 56000.0, \"Russia\"),\n    (15, \"Mia Lee\", \"Female\", 61000.0, \"China\")\n]\n\nemp_columns = [\"empId\", \"empName\", \"empGender\", \"empSalary\", \"empCountry\"]\n\ndf = spark.createDataFrame(emp_data,emp_columns)\ndf.show()\ndf.printSchema()\ndf.count()"}, {"cell_type": "markdown", "id": "1721e397-20dc-4932-9e80-15855f1a06d6", "metadata": {}, "source": "## `load df to CSV file`"}, {"cell_type": "code", "execution_count": 4, "id": "cb70b5a1-a82a-4903-8465-c2d002cd557c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "CSV_SINK_PATH = \"gs://landing-01-31-2024/sink/csv_file\"\n\ndf.coalesce(1).write.csv(CSV_SINK_PATH, header=True)"}, {"cell_type": "markdown", "id": "82c1fdee-a6ec-44b6-9be9-e5d8535e4a42", "metadata": {}, "source": "#"}, {"cell_type": "markdown", "id": "8e688a21-2531-46b9-b474-48bee5bf4588", "metadata": {}, "source": "## `load df to text file`"}, {"cell_type": "code", "execution_count": null, "id": "6347109e", "metadata": {}, "outputs": [], "source": "from pyspark.sql.functions import concat_ws\n\ndf1 = df.select([col(c).cast(\"string\") for c in df.columns])\n\ndf2 = df1.withColumn(\"concat\", concat_ws(\"\\t\", *df.columns))\n\ndf3 = df2.select(col(\"concat\"))\n\nTEXT_SINK_PATH = \"gs://random-bucket-morning-730/txt1_file\"\n\ndf3.coalesce(1).write.text(TEXT_SINK_PATH)"}, {"cell_type": "markdown", "id": "b890c5a1-c509-483c-bc88-cdeb159ecb09", "metadata": {}, "source": "#"}, {"cell_type": "markdown", "id": "392afd57-578e-4848-954f-b17250cdac96", "metadata": {}, "source": "## `load df to json file`"}, {"cell_type": "code", "execution_count": 5, "id": "7b5e0abc-9d3c-4a4d-a79e-de086a048dff", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "JSON_SINK_PATH = \"gs://landing-01-31-2024/sink/json_file\"\n\ndf.coalesce(1).write.json(JSON_SINK_PATH)"}, {"cell_type": "markdown", "id": "b3fce606-ab23-472e-b590-bb9bdc7de850", "metadata": {}, "source": "#"}, {"cell_type": "markdown", "id": "bcfc0828-23a8-4a8c-94f0-490c0c8e9419", "metadata": {}, "source": "## `load df to parquet file`"}, {"cell_type": "code", "execution_count": 9, "id": "6e5d639d-be66-4fce-8818-12f566049977", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "PAR_SINK_PATH = \"gs://landing-01-31-2024/sink/parquet_file\"\n\ndf.repartition(1).write.parquet(PAR_SINK_PATH)"}, {"cell_type": "markdown", "id": "da21670a-f7aa-4e0b-9ef1-7e023c08cafd", "metadata": {}, "source": "#"}, {"cell_type": "markdown", "id": "660d6626-3c6b-48ad-910e-af0a5d0f80c2", "metadata": {}, "source": "## `load df to mysql table`"}, {"cell_type": "code", "execution_count": null, "id": "98349268-e79e-4b9b-89a6-33189f722183", "metadata": {}, "outputs": [], "source": "mysql_properties = {\n    \"driver\" : \"com.mysql.cj.jdbc.Drviver\",\n    \"url\" : \"jdbc:mysql://<HOST-IP>:3306/<DB-NAME>\",\n    \"user\" : \"mysql\",\n    \"password\" : \"mypass\",\n    \"table\" : \"pysparkTable\"\n}\n\n(df.write\n    .format(\"jdbc\")\n    .options(mysql_properties)\n    .mode(\"overwrite\")\n    .save())"}, {"cell_type": "markdown", "id": "dff0a9a0-7088-4561-b7e1-fefa0a2012e9", "metadata": {}, "source": "#"}, {"cell_type": "markdown", "id": "5089a3f1-be85-4b40-a632-72267b5def6c", "metadata": {}, "source": "## `load df to bq table`"}, {"cell_type": "code", "execution_count": 12, "id": "d9162e81-be60-4474-8d91-2c448818177d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "\n\nTABLE_ID = \"winter-cocoa-412902.master_ds.pysparkTable\"\n\n(df.write\n    .format(\"bigquery\")\n    .option(\"table\", TABLE_ID)\n    .option(\"temporaryGcsBucket\", \"landing-01-31-2024/sink/temp\")\n    .mode(\"overwrite\")\n    .save())"}, {"cell_type": "code", "execution_count": null, "id": "9ce12c45-4373-43e5-91a4-66a99f716891", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}